{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c674ff83",
   "metadata": {},
   "source": [
    "1. [Configuration](#configuration)\n",
    "2. [Model & Tokenizer](#model)\n",
    "3. [Datasets](#datasets)\n",
    "4. [Training](#training)\n",
    "5. [Inference](#inference)\n",
    "6. [Embeddings](#embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2b31d88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plotly-express in /home/ec2-user/anaconda3/envs/python_p38/lib/python3.8/site-packages (0.4.1)\n",
      "Requirement already satisfied: pandas>=0.20.0 in /home/ec2-user/anaconda3/envs/python_p38/lib/python3.8/site-packages (from plotly-express) (1.4.3)\n",
      "Requirement already satisfied: plotly>=4.1.0 in /home/ec2-user/anaconda3/envs/python_p38/lib/python3.8/site-packages (from plotly-express) (5.10.0)\n",
      "Requirement already satisfied: scipy>=0.18 in /home/ec2-user/anaconda3/envs/python_p38/lib/python3.8/site-packages (from plotly-express) (1.7.3)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in /home/ec2-user/anaconda3/envs/python_p38/lib/python3.8/site-packages (from plotly-express) (0.13.2)\n",
      "Requirement already satisfied: numpy>=1.11 in /home/ec2-user/anaconda3/envs/python_p38/lib/python3.8/site-packages (from plotly-express) (1.21.5)\n",
      "Requirement already satisfied: patsy>=0.5 in /home/ec2-user/anaconda3/envs/python_p38/lib/python3.8/site-packages (from plotly-express) (0.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ec2-user/anaconda3/envs/python_p38/lib/python3.8/site-packages (from pandas>=0.20.0->plotly-express) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/python_p38/lib/python3.8/site-packages (from pandas>=0.20.0->plotly-express) (2022.2.1)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/python_p38/lib/python3.8/site-packages (from patsy>=0.5->plotly-express) (1.16.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /home/ec2-user/anaconda3/envs/python_p38/lib/python3.8/site-packages (from plotly>=4.1.0->plotly-express) (8.0.1)\n",
      "Requirement already satisfied: packaging>=21.3 in /home/ec2-user/anaconda3/envs/python_p38/lib/python3.8/site-packages (from statsmodels>=0.9.0->plotly-express) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/python_p38/lib/python3.8/site-packages (from packaging>=21.3->statsmodels>=0.9.0->plotly-express) (3.0.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: nbformat in /home/ec2-user/anaconda3/envs/python_p38/lib/python3.8/site-packages (5.4.0)\n",
      "Requirement already satisfied: jupyter-core in /home/ec2-user/anaconda3/envs/python_p38/lib/python3.8/site-packages (from nbformat) (4.11.1)\n",
      "Requirement already satisfied: traitlets>=5.1 in /home/ec2-user/anaconda3/envs/python_p38/lib/python3.8/site-packages (from nbformat) (5.3.0)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /home/ec2-user/anaconda3/envs/python_p38/lib/python3.8/site-packages (from nbformat) (4.14.0)\n",
      "Requirement already satisfied: fastjsonschema in /home/ec2-user/anaconda3/envs/python_p38/lib/python3.8/site-packages (from nbformat) (2.16.1)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /home/ec2-user/anaconda3/envs/python_p38/lib/python3.8/site-packages (from jsonschema>=2.6->nbformat) (5.9.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /home/ec2-user/anaconda3/envs/python_p38/lib/python3.8/site-packages (from jsonschema>=2.6->nbformat) (0.18.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /home/ec2-user/anaconda3/envs/python_p38/lib/python3.8/site-packages (from jsonschema>=2.6->nbformat) (22.1.0)\n",
      "Requirement already satisfied: pkgutil-resolve-name>=1.3.10 in /home/ec2-user/anaconda3/envs/python_p38/lib/python3.8/site-packages (from jsonschema>=2.6->nbformat) (1.3.10)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/ec2-user/anaconda3/envs/python_p38/lib/python3.8/site-packages (from importlib-resources>=1.4.0->jsonschema>=2.6->nbformat) (3.8.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install plotly-express\n",
    "%pip install --upgrade nbformat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f21c3122",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python_p38/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from datasets import load_metric\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, BertForPreTraining\n",
    "\n",
    "import umap\n",
    "\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'true'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb91c2cd",
   "metadata": {},
   "source": [
    "## 1. Configuration <a class=\"anchor\" id=\"configuration\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34cd4cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "VERSION = 1\n",
    "val_split = 0.1\n",
    "\n",
    "n_epochs = 5\n",
    "resume_from_checkpoint = True\n",
    "\n",
    "MODEL_NAME = \"dccuchile/bert-base-spanish-wwm-uncased\"\n",
    "\n",
    "\n",
    "BATCH_SIZE = 14\n",
    "\n",
    "# All classes\n",
    "ALL_CLASSES_V = ['negativo', 'positivo']\n",
    "N_CLASSES = len(ALL_CLASSES_V)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec0aa9af",
   "metadata": {},
   "source": [
    "## 2. Model & Tokenizer <a class=\"anchor\" id=\"model\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d702690",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8553f7ac",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /home/ec2-user/SageMaker/mlm_training/BETO_Conversaciones/checkpoint-34170 were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at /home/ec2-user/SageMaker/mlm_training/BETO_Conversaciones/checkpoint-34170 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained('/home/ec2-user/SageMaker/mlm_training/BETO_Conversaciones/checkpoint-34170',\n",
    "                                                          num_labels=N_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d791d3",
   "metadata": {},
   "source": [
    "## 3. Datasets <a class=\"anchor\" id=\"datasets\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09edbe24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DS:\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset_df,\n",
    "        tokenizer,\n",
    "        training=False,\n",
    "        split_seed=42,\n",
    "        val_split=0.15,\n",
    "        n_pad=512,\n",
    "    ):\n",
    "        \n",
    "        self.training = training\n",
    "        self.dataset_df = dataset_df.set_index('num_id')\n",
    "        self.tokenizer = tokenizer\n",
    "        self.n_pad = n_pad\n",
    "        \n",
    "        self.all_conv_v = dataset_df.num_id.unique()\n",
    "        \n",
    "        n_trn_samples = int( self.all_conv_v.shape[0] * (1 - val_split) )\n",
    "        \n",
    "        np.random.seed(split_seed)\n",
    "        idx_v = np.random.permutation(self.all_conv_v.shape[0])\n",
    "        np.random.seed(None)\n",
    "        \n",
    "        if self.training:\n",
    "            self.all_conv_v = self.all_conv_v[:n_trn_samples]\n",
    "        else:\n",
    "            self.all_conv_v = self.all_conv_v[n_trn_samples:]\n",
    "        \n",
    "        return None\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        sample_id = self.all_conv_v[idx]\n",
    "        \n",
    "        conv_df = self.dataset_df.loc[sample_id]\n",
    "        \n",
    "        \n",
    "        lines_v = conv_df.des_message.values\n",
    "        max_len = 3 * self.n_pad // len(lines_v)\n",
    "        \n",
    "        text = '[SEP]'.join( [' '.join( l.split(' ')[:max_len] ) for l in lines_v] )\n",
    "        \n",
    "        inputs = self.tokenizer(\n",
    "            text,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            max_length=self.n_pad,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "        \n",
    "        \n",
    "        data = {\n",
    "            'sample_id':sample_id,\n",
    "            'conv_df':conv_df,\n",
    "            \n",
    "            'text': text,\n",
    "            'label': torch.tensor( conv_df['cls'].iloc[0], dtype=torch.int64),\n",
    "        }\n",
    "        \n",
    "        for k in inputs.keys():\n",
    "            data[k] = inputs[k][0]\n",
    "        \n",
    "        return data\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.all_conv_v)\n",
    "    \n",
    "    \n",
    "    def collate_fn(self, data_v):\n",
    "        keys_v = tuple( data_v[0].keys() )\n",
    "        ret_d = {k: list() for k in keys_v}\n",
    "        \n",
    "        for k in keys_v:\n",
    "            for data in data_v:\n",
    "                ret_d[k].append( data[k] )\n",
    "        \n",
    "        for k in keys_v:\n",
    "            if type( ret_d[k][0] ) is torch.Tensor:\n",
    "                ret_d[k] = torch.stack( ret_d[k] )\n",
    "            \n",
    "            elif type( ret_d[k][0] ) is transformers.tokenization_utils_base.BatchEncoding:\n",
    "                inputs = self.collate_fn(ret_d[k])                \n",
    "                ret_d[k] = transformers.tokenization_utils_base.BatchEncoding(inputs)\n",
    "            \n",
    "            else:\n",
    "                ret_d[k] = np.array( ret_d[k], dtype=np.object_ )\n",
    "                \n",
    "        return ret_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e24ff4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df = pd.read_csv('data/dataset_df_inactivation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2417bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_trn = DS(\n",
    "    dataset_df,\n",
    "    tokenizer,\n",
    "    training=True,\n",
    "    val_split=val_split,\n",
    "    split_seed=SEED,\n",
    ")\n",
    "\n",
    "ds_val = DS(\n",
    "    dataset_df,\n",
    "    tokenizer,\n",
    "    training=False,\n",
    "    val_split=val_split,\n",
    "    split_seed=SEED,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a181143",
   "metadata": {},
   "source": [
    "## 4. Training <a class=\"anchor\" id=\"training\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "021434ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = load_metric(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a0b7b416",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=f\"inactivation_models_v{VERSION}\",\n",
    "    num_train_epochs=float(n_epochs),\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    \n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=2*BATCH_SIZE,\n",
    "    gradient_accumulation_steps=1,\n",
    "    \n",
    "    resume_from_checkpoint=resume_from_checkpoint,\n",
    "    save_strategy='epoch',\n",
    "    \n",
    "    metric_for_best_model='accuracy',\n",
    "    load_best_model_at_end=True,\n",
    "    greater_is_better=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd6a2d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    #data_collator=ds_trn.collate_fn,\n",
    "    train_dataset=ds_trn,\n",
    "    eval_dataset=ds_val,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299dbc20",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python_p38/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 4797\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 14\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 14\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1715\n",
      "The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: conv_df, sample_id, text. If conv_df, sample_id, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1715' max='1715' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1715/1715 1:16:25, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.128085</td>\n",
       "      <td>0.962477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.150200</td>\n",
       "      <td>0.161989</td>\n",
       "      <td>0.956848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.070200</td>\n",
       "      <td>0.192015</td>\n",
       "      <td>0.954972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.070200</td>\n",
       "      <td>0.217709</td>\n",
       "      <td>0.956848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.020400</td>\n",
       "      <td>0.262788</td>\n",
       "      <td>0.953096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 533\n",
      "  Batch size = 28\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: conv_df, sample_id, text. If conv_df, sample_id, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "Saving model checkpoint to inactivation_models_v1/checkpoint-343\n",
      "Configuration saved in inactivation_models_v1/checkpoint-343/config.json\n",
      "Model weights saved in inactivation_models_v1/checkpoint-343/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 533\n",
      "  Batch size = 28\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: conv_df, sample_id, text. If conv_df, sample_id, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "Saving model checkpoint to inactivation_models_v1/checkpoint-1029\n",
      "Configuration saved in inactivation_models_v1/checkpoint-1029/config.json\n",
      "Model weights saved in inactivation_models_v1/checkpoint-1029/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 533\n",
      "  Batch size = 28\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: conv_df, sample_id, text. If conv_df, sample_id, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "Saving model checkpoint to inactivation_models_v1/checkpoint-1372\n",
      "Configuration saved in inactivation_models_v1/checkpoint-1372/config.json\n",
      "Model weights saved in inactivation_models_v1/checkpoint-1372/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 533\n",
      "  Batch size = 28\n",
      "The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: conv_df, sample_id, text. If conv_df, sample_id, text are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "Saving model checkpoint to inactivation_models_v1/checkpoint-1715\n",
      "Configuration saved in inactivation_models_v1/checkpoint-1715/config.json\n",
      "Model weights saved in inactivation_models_v1/checkpoint-1715/pytorch_model.bin\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from inactivation_models_v1/checkpoint-343 (score: 0.9624765478424016).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1715, training_loss=0.07114963211749108, metrics={'train_runtime': 4588.7254, 'train_samples_per_second': 5.227, 'train_steps_per_second': 0.374, 'total_flos': 6310718662809600.0, 'train_loss': 0.07114963211749108, 'epoch': 5.0})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8293d884",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.exit(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d0ead4",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ac9bc75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file inactivation_models_v1/checkpoint-343/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"inactivation_models_v1/checkpoint-343\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.21.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 31002\n",
      "}\n",
      "\n",
      "loading weights file inactivation_models_v1/checkpoint-343/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at inactivation_models_v1/checkpoint-343.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    #'inactivation_models_v99/checkpoint-1372'\n",
    "    'inactivation_models_v1/checkpoint-343'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b159f0ec",
   "metadata": {},
   "source": [
    "## 5. Inference <a class=\"anchor\" id=\"inference\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1a0bad0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, dl, return_targets=True, device='cpu'):\n",
    "    preds_v  = []\n",
    "    label_v = []\n",
    "    probs_v  = []\n",
    "    \n",
    "    \n",
    "    if model.training:\n",
    "        model.eval()\n",
    "    \n",
    "    model.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(dl):\n",
    "\n",
    "            logits = model(\n",
    "                input_ids=data['input_ids'].to(device),\n",
    "                token_type_ids=data['token_type_ids'].to(device),\n",
    "                attention_mask=data['attention_mask'].to(device),\n",
    "            )['logits']\n",
    "\n",
    "\n",
    "            probs = logits.softmax(axis=-1).detach().cpu().numpy()\n",
    "            preds = probs.argmax(axis=-1)\n",
    "\n",
    "            probs_v.append(probs)\n",
    "            preds_v.append(preds)\n",
    "\n",
    "            if return_targets:\n",
    "                label = data['label'].detach().cpu().numpy()\n",
    "                label_v.append(label)\n",
    "\n",
    "    probs_v = np.concatenate(probs_v)\n",
    "    preds_v = np.concatenate(preds_v)\n",
    "    \n",
    "    ret_d = {\n",
    "        'probs':probs_v,\n",
    "        'preds':preds_v,\n",
    "    }    \n",
    "    \n",
    "    if return_targets:\n",
    "        label_v = np.concatenate(label_v)\n",
    "        ret_d['label'] = label_v\n",
    "    \n",
    "    return ret_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a74ba121",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_trn = DataLoader(ds_trn, batch_size=2*BATCH_SIZE, collate_fn=ds_trn.collate_fn, shuffle=True)\n",
    "dl_val = DataLoader(ds_val, batch_size=2*BATCH_SIZE, collate_fn=ds_val.collate_fn, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0be1ab",
   "metadata": {},
   "source": [
    "### Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e8f5e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 172/172 [05:20<00:00,  1.86s/it]\n"
     ]
    }
   ],
   "source": [
    "trn_preds_d = eval_model(model, dl_trn, device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4d9292d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: ds_trn\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.99      0.99      0.99      3515\n",
      "    positivo       0.96      0.97      0.97      1282\n",
      "\n",
      "    accuracy                           0.98      4797\n",
      "   macro avg       0.98      0.98      0.98      4797\n",
      "weighted avg       0.98      0.98      0.98      4797\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Classification Report: ds_trn')\n",
    "report_str = classification_report(\n",
    "    y_true=trn_preds_d['label'],\n",
    "    y_pred=trn_preds_d['preds'],\n",
    "    target_names=ALL_CLASSES_V,\n",
    "    digits=2,\n",
    "    zero_division=1,\n",
    ")\n",
    "\n",
    "print( report_str )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d12dca",
   "metadata": {},
   "source": [
    "### Validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06e63290",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:35<00:00,  1.79s/it]\n"
     ]
    }
   ],
   "source": [
    "val_preds_d = eval_model(model, dl_val, device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e75e98ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: ds_val\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negativo       0.98      0.97      0.97       384\n",
      "    positivo       0.93      0.94      0.93       149\n",
      "\n",
      "    accuracy                           0.96       533\n",
      "   macro avg       0.95      0.96      0.95       533\n",
      "weighted avg       0.96      0.96      0.96       533\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Classification Report: ds_val')\n",
    "report_str = classification_report(\n",
    "    y_true=val_preds_d['label'],\n",
    "    y_pred=val_preds_d['preds'],\n",
    "    target_names=ALL_CLASSES_V,\n",
    "    digits=2,\n",
    "    zero_division=1,\n",
    ")\n",
    "\n",
    "print( report_str )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fcb123",
   "metadata": {},
   "source": [
    "## Plot embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42975209",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model_interaction(model, dl, return_targets=True, add_int_idx=True, device='cpu'):\n",
    "    embed_lhs_v  = []\n",
    "    embed_po_v = []\n",
    "    label_v = []\n",
    "    sample_id_v = []\n",
    "    int_idx_v = []\n",
    "    \n",
    "    embed_model = model.bert\n",
    "    \n",
    "    if embed_model.training:\n",
    "        embed_model.eval()\n",
    "        \n",
    "    embed_model.to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(dl):\n",
    "\n",
    "            embeddings = embed_model(\n",
    "                input_ids=data['input_ids'].to(device),\n",
    "                token_type_ids=data['token_type_ids'].to(device),\n",
    "                attention_mask=data['attention_mask'].to(device),\n",
    "            )\n",
    "\n",
    "            embed_lhs = embeddings['last_hidden_state'][:,0,:].detach().cpu().numpy()\n",
    "            embed_po = embeddings['pooler_output'].detach().cpu().numpy()\n",
    "\n",
    "            embed_lhs_v.append(embed_lhs)\n",
    "            embed_po_v.append(embed_po)\n",
    "\n",
    "            sample_id_v.append( data['sample_id'] )\n",
    "            \n",
    "            if add_int_idx:\n",
    "                int_idx_v.append( data['int_idx'] )\n",
    "\n",
    "            if return_targets:\n",
    "                label = data['label'].detach().cpu().numpy()\n",
    "                label_v.append(label)\n",
    "\n",
    "    embed_lhs_v = np.concatenate(embed_lhs_v)\n",
    "    embed_po_v = np.concatenate(embed_po_v)\n",
    "    sample_id_v = np.concatenate(sample_id_v)\n",
    "    \n",
    "    \n",
    "    ret_d = {\n",
    "        'embed_lhs' :embed_lhs_v,\n",
    "        'embed_po': embed_po_v,\n",
    "        'sample_id': sample_id_v,\n",
    "        'int_idx': int_idx_v,\n",
    "    }    \n",
    "    \n",
    "    if return_targets:\n",
    "        label_v = np.concatenate(label_v)\n",
    "        ret_d['label'] = label_v\n",
    "    \n",
    "    if add_int_idx:\n",
    "        int_idx_v = np.concatenate(int_idx_v)\n",
    "        ret_d['int_idx'] = int_idx_v\n",
    "        \n",
    "    return ret_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a378f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:32<00:00,  1.63s/it]\n"
     ]
    }
   ],
   "source": [
    "val_embeddings_d = eval_model_interaction(model, dl_val, return_targets=True, add_int_idx=False, device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "308d0ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = val_embeddings_d['embed_po']\n",
    "\n",
    "umap_2d_po = umap.UMAP(n_components=2, init='random', random_state=0, n_neighbors=20)\n",
    "proj_2d_po = umap_2d_po.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3ea1e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_po = pd.DataFrame(data=proj_2d_po, index=None, columns=['x', 'y'])\n",
    "df_po['cls'] = val_embeddings_d['label']\n",
    "df_po['label'] = df_po['cls'].replace({0: 'negativo', 1: 'positivo'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "511b713d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig = px.scatter(df_po, x='x', y='y', color='label', title='Por conversación - Pooler output')\n",
    "#fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65ae135b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Promesa de pago                                         35182\n",
       "Renuencia                                               17973\n",
       "No lo conocen                                            5839\n",
       "Con intención de pago, falta concretar negociación       5048\n",
       "Acepto recado                                            1549\n",
       "Confirmo Pago completo en tiempo y forma                 1476\n",
       "Ya no vive/trabaja ahí                                   1262\n",
       "Confirma próximo pago en fecha                            722\n",
       "Informa pago realizado                                    509\n",
       "Ratifica promesa de pago                                  482\n",
       "Producto de apoyo                                         477\n",
       "No Promesa / No compromete Pago                           465\n",
       "No contestan /No hay nadie                                426\n",
       "Ya no tiene contacto con titular                          267\n",
       "Interacción incompleta                                    229\n",
       "Otra razón                                                207\n",
       "Pago realizado                                            165\n",
       "No acepto recado                                          133\n",
       "No confirma próximo pago                                  102\n",
       "Recado en Buzón o con tercero                             100\n",
       "Promesa de pago 3ero                                       87\n",
       "Recado / Notificación en buzón o con tercero               85\n",
       "Recado con familiar o tercero                              79\n",
       "No aplica                                                  67\n",
       "Cuelgan / Se rehusan a abrir                               66\n",
       "Para poner al corriente: Pago 100% Capital Vencido         63\n",
       "Con intención de pago, falta concretar negociación\\t       46\n",
       "Cita telefonica                                            43\n",
       "Queja, aclaración, pide devolución                         39\n",
       "No conforme con condiciones de crédito                     38\n",
       "Convenio de pago largo plazo                               35\n",
       "Se deja notificación con tercero o bajo puerta             30\n",
       "Dudas sobre mi crédito                                     27\n",
       "Con Problemática - Evaluará opciones                       21\n",
       "Teléfono Invalido / Domicilio no ubicado                   19\n",
       "Confirmo pago en tiempo pero parcial                       15\n",
       "Teléfono fuera de servicio/ Domicilio abandonado           11\n",
       "Name: outcome, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df.outcome.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c09bbd7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Promesa de pago                                         35182\n",
       "Renuencia                                               17973\n",
       "Con intención de pago, falta concretar negociación       5048\n",
       "Acepto recado                                            1549\n",
       "Confirmo Pago completo en tiempo y forma                 1476\n",
       "Confirma próximo pago en fecha                            722\n",
       "Informa pago realizado                                    509\n",
       "Ratifica promesa de pago                                  482\n",
       "Producto de apoyo                                         477\n",
       "No Promesa / No compromete Pago                           465\n",
       "Interacción incompleta                                    229\n",
       "Otra razón                                                207\n",
       "Pago realizado                                            165\n",
       "No acepto recado                                          133\n",
       "No confirma próximo pago                                  102\n",
       "Recado en Buzón o con tercero                             100\n",
       "Promesa de pago 3ero                                       87\n",
       "Recado / Notificación en buzón o con tercero               85\n",
       "Recado con familiar o tercero                              79\n",
       "No aplica                                                  67\n",
       "Cuelgan / Se rehusan a abrir                               66\n",
       "Para poner al corriente: Pago 100% Capital Vencido         63\n",
       "Con intención de pago, falta concretar negociación\\t       46\n",
       "Cita telefonica                                            43\n",
       "Queja, aclaración, pide devolución                         39\n",
       "No conforme con condiciones de crédito                     38\n",
       "Convenio de pago largo plazo                               35\n",
       "Se deja notificación con tercero o bajo puerta             30\n",
       "Dudas sobre mi crédito                                     27\n",
       "Con Problemática - Evaluará opciones                       21\n",
       "Confirmo pago en tiempo pero parcial                       15\n",
       "Name: outcome, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df.loc[dataset_df['cls']==0].outcome.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a4bd1c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No lo conocen                                       5839\n",
       "Ya no vive/trabaja ahí                              1262\n",
       "No contestan /No hay nadie                           426\n",
       "Ya no tiene contacto con titular                     267\n",
       "Teléfono Invalido / Domicilio no ubicado              19\n",
       "Teléfono fuera de servicio/ Domicilio abandonado      11\n",
       "Name: outcome, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df.loc[dataset_df['cls']==1].outcome.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fec869",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
